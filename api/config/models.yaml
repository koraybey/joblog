local:
  repo_id: TheBloke/OpenHermes-2.5-Mistral-7B-GGUF
  model:  openhermes-2.5-mistral-7b.Q8_0.gguf
  embed_model: BAAI/bge-m3
  tokenizer: TheBloke/OpenHermes-2.5-Mistral-7B-AWQ
  n_ctx: 8192
  max_tokens: 4069
  temperature: 0.6

server:
  host: 0.0.0.0
  port: 8080
  backend: llamacpp
  repo_id: TheBloke/OpenHermes-2.5-Mistral-7B-GGUF
  model:  openhermes-2.5-mistral-7b.Q8_0.gguf
  embed_model: BAAI/bge-m3
  tokenizer: TheBloke/OpenHermes-2.5-Mistral-7B-AWQ
  n_ctx: 8192
  max_tokens: 4069
  temperature: 0.2

mistral:
  model: mistral-medium
  embed_model: mistral-embed
  max_tokens: 4096
  temperature: 0.2

openai:
  model: gpt-3.5-turbo-1106
  embed_model: text-embedding-3-small
  max_tokens: 4096
  temperature: 0.2
